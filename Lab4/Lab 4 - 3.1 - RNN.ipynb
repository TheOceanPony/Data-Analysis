{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import - Clickbait title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snoopy Got A Star On The Walk Of Fame And Seem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15 Tweets That Are Too Real For Anyone Who Has...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Try To Stay Calm '90s Kids, But The \"Full Hous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1 Pico Projector Stands Out From a Small Crowd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBA: Gilbert Arenas and Javaris Crittenton sus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Clickbait\n",
       "0  Snoopy Got A Star On The Walk Of Fame And Seem...           1\n",
       "1  15 Tweets That Are Too Real For Anyone Who Has...           1\n",
       "2  Try To Stay Calm '90s Kids, But The \"Full Hous...           1\n",
       "3    P1 Pico Projector Stands Out From a Small Crowd           0\n",
       "4  NBA: Gilbert Arenas and Javaris Crittenton sus...           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"clickbait_ds.csv\", delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32000 entries, 0 to 31999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Text        32000 non-null  object\n",
      " 1    Clickbait  32000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 500.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(str_x):\n",
    "    words = str_x.split(' ')\n",
    "    neutral_words = ['one', 'say', 'page', 'know', 'go', 'back', 'take', 'see', 'look', 'article',\n",
    "                     'edit', 'got', 'thing', 'want', 'make', 'people']\n",
    "    new_words = list()\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english') or word not in neutral_words:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ocean\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"Text\"] = df[\"Text\"].map(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "df[\"Text\"] = df[\"Text\"].map(lambda x: x.lower())\n",
    "df[\"Text\"] = df[\"Text\"].map(delete_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df[\"Text\"].values).toarray()\n",
    "Y = df.iloc[:, 1].values\n",
    "\n",
    "num_samples = 500 #X.shape[0]\n",
    "train_samples = int(0.75*num_samples)\n",
    "\n",
    "indexes = np.arange(num_samples)\n",
    "random.shuffle(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 22761) (375,)\n",
      "(125, 22761) (125,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = X[indexes], Y[indexes]\n",
    "x_train, y_train = X[:train_samples, :], Y[:train_samples]\n",
    "x_test, y_test = X[train_samples:, :], Y[train_samples:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(22761, 1))\n",
    "\n",
    "x = keras.layers.LSTM(128)(inputs)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 22761, 1)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = keras.Model(inputs=inputs, outputs=outputs, name=\"rnn_model\")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 511s 7s/step - loss: 0.0000e+00 - accuracy: 0.4519 - val_loss: 0.0000e+00 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ddb5245040>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(x_train, y_train, batch_size=4, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 10s - loss: 0.0000e+00 - accuracy: 0.4240\n",
      "Test loss: 0.0\n",
      "Test accuracy: 0.42399999499320984\n"
     ]
    }
   ],
   "source": [
    "test_scores = rnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f\"Test loss: {test_scores[0]}  |  Test accuracy:\", test_scores[1])\n",
    "print(\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
